# -*- coding: utf-8 -*-
"""Cancer_Detector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YlDI5LV2jzHiuf_Wo3yBLTdbO6WpauC4
"""

#Description : This program detect breast cancer, based off of data.

#import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Load the data
from google.colab import files
uploaded = files.upload()
df = pd.read_csv('data.csv')
df.head(7)

#count the number of rows and columns in the data set
df.shape

#Count the number of empty(NaN, NAN, na) values in each coloumn
df.isna().sum()

#drop the column with all missing values 
#clean the data set by removing repeated and empty values
df = df.dropna(axis = 1)

#get the new count of the number of rows and columns
df.shape

#get a count of the number of Malignant (M) or Benign (B) cells
df['diagnosis'].value_counts()

#visualize the count
sns.countplot(df['diagnosis'], label='count')

#look at the data types to see which columns need to be encoded
df.dtypes

#Encode the categorical data values
from sklearn.preprocessing import LabelEncoder
labelencoder_Y = LabelEncoder()
df.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values)

df.iloc[:,1]

#create a pair plot
sns.pairplot(df.iloc[:,1:6], hue= 'diagnosis')

#print the first 5 rows of the new data
df.head(5)

#get the correlation of the columns
df.iloc[:,1:12].corr()

#visualize the correlation
plt.figure(figsize=(10,10))
sns.heatmap(df.iloc[:,1:12].corr(), annot=True, fmt='.0%')

#split the data set into independent (x) and dependent (y) data sets
X = df.iloc[:,2:31].values
Y = df.iloc[:,1].values

#split the data set into 75% training and 25% testing
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)

#scale the data / Feature Scaling
from sklearn.preprocessing import  StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

#create a function for the model
def models(X_train,Y_train):

  #import Logistic Regression
  from sklearn.linear_model import LogisticRegression
  log = LogisticRegression(random_state = 0)
  #train the regression using data
  log.fit(X_train, Y_train)

  #Decision Tree
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion = 'entropy', random_state=0)
  tree.fit(X_train, Y_train)

  #Random Force
  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators = 10,criterion = 'entropy', random_state=0 )
  forest.fit(X_train,Y_train)

  #print the model accuracy on the training data
  print('[0] Logistic Regression Training Accuracy: ',log.score(X_train, Y_train))
  print('[1] Decision Tree Classifier Training Accuracy: ',tree.score(X_train, Y_train))
  print('[2] Random Forest Classifier Training Accuracy: ',forest.score(X_train, Y_train))

  return log, tree, forest

#getting all of the models
model = models(X_train=X_train,Y_train=Y_train)

#test models accuracy on test data on confusuion matrix
from sklearn.metrics import confusion_matrix

for i in range ( len(model)):
  print('Model ',i)
  cm = confusion_matrix(Y_test,model[i].predict(X_test))

  TP = cm[0][0]
  FP = cm[1][0]
  TN = cm[1][1]
  FN = cm[0][1]

  print(cm)
  print('Testing Accuracy = ',(TP+TN)/(TP+TN+FN+FP))
  print()

#data report
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

for i in range ( len(model)):
  print('Model ',i)
  print( classification_report(Y_test, model[i].predict(X_test)))
  print( accuracy_score(Y_test, model[i].predict(X_test)))
  print()

#Print the prediction of Random Forest Classifier Model
pred = model[2].predict(X_test)
print('Model Prediction')
print(pred)

print('\nActual Data')
print(Y_test)